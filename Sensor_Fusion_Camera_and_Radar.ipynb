{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omprabhu98/MEngCapstone2022/blob/main/Sensor_Fusion_Camera_and_Radar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjBDj97y9k18"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vwz1UzMu9mF-"
      },
      "outputs": [],
      "source": [
        "# Tensorflow\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "# I/O libraries\n",
        "import os\n",
        "from io import BytesIO\n",
        "import tarfile\n",
        "import tempfile\n",
        "from six.moves import urllib\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib\n",
        "import torch\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "from tqdm import tqdm\n",
        "import IPython\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Comment this out if you want to see Deprecation warnings\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwkf2tnYQKAT",
        "outputId": "98d4998f-c98a-47cd-ceb9-15f0490b9339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install timm;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdsigyfAhITX",
        "outputId": "d4fa4e4e-7e54-4e10-9a3d-beb941c74877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MEngCapstone2022'...\n",
            "remote: Enumerating objects: 310, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 310 (delta 50), reused 27 (delta 15), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (310/310), 217.92 MiB | 31.63 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n",
            "Downloading Point_Cloud/sensor_points_100_frames.npy (641 MB)\n",
            "Error downloading object: Point_Cloud/sensor_points_100_frames.npy (e6a9e86): Smudge error: Error downloading Point_Cloud/sensor_points_100_frames.npy (e6a9e864134afd2654ffba80034f0350edcb1fc173f3830c7ab1f446e2e4934c): batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\n",
            "\n",
            "Errors logged to /content/MEngCapstone2022/.git/lfs/logs/20231015T213617.528630255.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: Point_Cloud/sensor_points_100_frames.npy: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n",
            "MEngCapstone2022  sample_data\n",
            "'Depth Prediction'\t\t\t     README.md\n",
            "'Image Segmentation'\t\t\t     SAR+Camera_Fusion\n",
            " Image_Segmentation_Depth_Prediction.ipynb   Sensor_Fusion_Camera_and_Radar.ipynb\n",
            " Point_Cloud\t\t\t\t     Videos\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/omprabhu98/MEngCapstone2022.git\n",
        "!ls\n",
        "os.chdir(\"MEngCapstone2022\")\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZANbjAERfC5",
        "outputId": "f11cc9e8-2056-49ae-b86e-2508c927a7ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jKEwPDK-Edp"
      },
      "source": [
        "# Functions for Image Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Xfj_GZ-FWL"
      },
      "outputs": [],
      "source": [
        "class DeepLabModel(object):\n",
        "    \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
        "\n",
        "    FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
        "\n",
        "    def __init__(self, tarball_path):\n",
        "        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
        "        self.graph = tf.Graph()\n",
        "        graph_def = None\n",
        "\n",
        "        # Extract frozen graph from tar archive.\n",
        "        tar_file = tarfile.open(tarball_path)\n",
        "        for tar_info in tar_file.getmembers():\n",
        "            if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
        "                file_handle = tar_file.extractfile(tar_info)\n",
        "                graph_def = tf.GraphDef.FromString(file_handle.read())\n",
        "                break\n",
        "        tar_file.close()\n",
        "\n",
        "        if graph_def is None:\n",
        "            raise RuntimeError('Cannot find inference graph in tar archive.')\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            tf.import_graph_def(graph_def, name='')\n",
        "        self.sess = tf.Session(graph=self.graph)\n",
        "\n",
        "    def run(self, image, INPUT_TENSOR_NAME = 'ImageTensor:0', OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'):\n",
        "        \"\"\"Runs inference on a single image.\n",
        "\n",
        "        Args:\n",
        "            image: A PIL.Image object, raw input image.\n",
        "            INPUT_TENSOR_NAME: The name of input tensor, default to ImageTensor.\n",
        "            OUTPUT_TENSOR_NAME: The name of output tensor, default to SemanticPredictions.\n",
        "\n",
        "        Returns:\n",
        "            resized_image: RGB image resized from original input image.\n",
        "            seg_map: Segmentation map of `resized_image`.\n",
        "        \"\"\"\n",
        "        width, height = image.size\n",
        "        target_size = (2049,1025)  # size of Cityscapes images\n",
        "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "        batch_seg_map = self.sess.run(\n",
        "            OUTPUT_TENSOR_NAME,\n",
        "            feed_dict={INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
        "        seg_map = batch_seg_map[0]  # expected batch size = 1\n",
        "        if len(seg_map.shape) == 2:\n",
        "            seg_map = np.expand_dims(seg_map,-1)  # need an extra dimension for cv.resize\n",
        "        seg_map = cv.resize(seg_map, (width,height), interpolation=cv.INTER_NEAREST)\n",
        "        return seg_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCIUhvfV-MiI"
      },
      "outputs": [],
      "source": [
        "def create_label_colormap():\n",
        "    \"\"\"Creates a label colormap used in Cityscapes segmentation benchmark.\n",
        "\n",
        "    Returns:\n",
        "        A Colormap for visualizing segmentation results.\n",
        "    \"\"\"\n",
        "    colormap = np.array([\n",
        "        [128,  64, 128],\n",
        "        [244,  35, 232],\n",
        "        [ 70,  70,  70],\n",
        "        [102, 102, 156],\n",
        "        [190, 153, 153],\n",
        "        [153, 153, 153],\n",
        "        [250, 170,  30],\n",
        "        [220, 220,   0],\n",
        "        [107, 142,  35],\n",
        "        [152, 251, 152],\n",
        "        [ 70, 130, 180],\n",
        "        [220,  20,  60],\n",
        "        [255,   0,   0],\n",
        "        [  0,   0, 142],\n",
        "        [  0,   0,  70],\n",
        "        [  0,  60, 100],\n",
        "        [  0,  80, 100],\n",
        "        [  0,   0, 230],\n",
        "        [119,  11,  32],\n",
        "        [  0,   0,   0]], dtype=np.uint8)\n",
        "    return colormap\n",
        "\n",
        "\n",
        "def label_to_color_image(label):\n",
        "    \"\"\"Adds color defined by the dataset colormap to the label.\n",
        "\n",
        "    Args:\n",
        "        label: A 2D array with integer type, storing the segmentation label.\n",
        "\n",
        "    Returns:\n",
        "        result: A 2D array with floating type. The element of the array\n",
        "            is the color indexed by the corresponding element in the input label\n",
        "            to the PASCAL color map.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If label is not of rank 2 or its value is larger than color\n",
        "            map maximum entry.\n",
        "    \"\"\"\n",
        "    if label.ndim != 2:\n",
        "        raise ValueError('Expect 2-D input label')\n",
        "\n",
        "    colormap = create_label_colormap()\n",
        "\n",
        "    if np.max(label) >= len(colormap):\n",
        "        raise ValueError('label value too large.')\n",
        "\n",
        "    return colormap[label]\n",
        "\n",
        "\n",
        "def vis_segmentation(image, seg_map):\n",
        "    \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
        "\n",
        "    plt.subplot(grid_spec[0])\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title('input image')\n",
        "\n",
        "    plt.subplot(grid_spec[1])\n",
        "    seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "    plt.imshow(seg_image)\n",
        "    plt.axis('off')\n",
        "    plt.title('segmentation map')\n",
        "\n",
        "    plt.subplot(grid_spec[2])\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(seg_image, alpha=0.7)\n",
        "    plt.axis('off')\n",
        "    plt.title('segmentation overlay')\n",
        "\n",
        "    unique_labels = np.unique(seg_map)\n",
        "    ax = plt.subplot(grid_spec[3])\n",
        "    plt.imshow(FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "    ax.yaxis.tick_right()\n",
        "    plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
        "    plt.xticks([], [])\n",
        "    ax.tick_params(width=0.0)\n",
        "    plt.grid('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "LABEL_NAMES = np.asarray([\n",
        "    'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "    'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck',\n",
        "    'bus', 'train', 'motorcycle', 'bicycle', 'void'])\n",
        "\n",
        "COLOR_MAP = np.array([\n",
        "    [128,  64, 128],\n",
        "    [244,  35, 232],\n",
        "    [ 70,  70,  70],\n",
        "    [102, 102, 156],\n",
        "    [190, 153, 153],\n",
        "    [153, 153, 153],\n",
        "    [250, 170,  30],\n",
        "    [220, 220,   0],\n",
        "    [107, 142,  35],\n",
        "    [152, 251, 152],\n",
        "    [ 70, 130, 180],\n",
        "    [220,  20,  60],\n",
        "    [255,   0,   0],\n",
        "    [  0,   0, 142],\n",
        "    [  0,   0,  70],\n",
        "    [  0,  60, 100],\n",
        "    [  0,  80, 100],\n",
        "    [  0,   0, 230],\n",
        "    [119,  11,  32],\n",
        "    [  0,   0,   0]], dtype=np.uint8)\n",
        "\n",
        "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
        "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxKiAGG_-QYw",
        "outputId": "95155fec-fac7-4860-a9e7-a0995dac6cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading model, this might take a while...\n",
            "download completed! loading DeepLab model...\n",
            "model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'mobilenetv2_coco_cityscapes_trainfine'\n",
        "#MODEL_NAME = 'xception65_cityscapes_trainfine'\n",
        "\n",
        "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
        "_MODEL_URLS = {\n",
        "    'mobilenetv2_coco_cityscapes_trainfine':\n",
        "        'deeplabv3_mnv2_cityscapes_train_2018_02_05.tar.gz',\n",
        "    'xception65_cityscapes_trainfine':\n",
        "        'deeplabv3_cityscapes_train_2018_02_06.tar.gz',\n",
        "}\n",
        "_TARBALL_NAME = 'deeplab_model.tar.gz'\n",
        "\n",
        "model_dir = tempfile.mkdtemp()\n",
        "tf.gfile.MakeDirs(model_dir)\n",
        "\n",
        "download_path = os.path.join(model_dir, _TARBALL_NAME)\n",
        "print('downloading model, this might take a while...')\n",
        "urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME], download_path)\n",
        "print('download completed! loading DeepLab model...')\n",
        "\n",
        "MODEL = DeepLabModel(download_path)\n",
        "print('model loaded successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVnUbIVY96HU"
      },
      "source": [
        "# Initialize Midas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW1E_emiQatf",
        "outputId": "c1a41e24-fbeb-4d65-9cb3-68a4939504d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywJyJpTzQtDR",
        "outputId": "69c3c785-a965-4c79-f229-af1decfe9fd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DPTDepthModel(\n",
              "  (pretrained): Module(\n",
              "    (model): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    )\n",
              "    (act_postprocess1): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "    )\n",
              "    (act_postprocess2): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (act_postprocess3): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act_postprocess4): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (scratch): Module(\n",
              "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (refinenet1): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet2): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet3): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet4): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (output_conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Interpolate()\n",
              "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4Da96O0Q06Z",
        "outputId": "f0fe33ea-564c-4333-e008-507f1dce0c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN0kU6NJ1Ye5",
        "outputId": "d8f89953-d593-4118-a038-602618fc6637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kja3q7PyhB4H"
      },
      "source": [
        "# Conversion to meters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoPzjnl5hCCS"
      },
      "outputs": [],
      "source": [
        "nb_photo=34\n",
        "\n",
        "equiv=[[0.001,51],    #for extrapolation\n",
        "      [0.1,45],     #premier plan\n",
        "      [0.9,42.3],\n",
        "      [1.8,37.4],\n",
        "      [2.7,28.7],\n",
        "      [3.6,24.443365],\n",
        "      [4.5,22.058018],\n",
        "      [5.4,15.317413],\n",
        "      [6.3,14.677493],\n",
        "      [7.2,10.969739],\n",
        "      [8.1,10.883035],\n",
        "      [9,9.883035],\n",
        "      [9.9,8.058806],\n",
        "      [10.8,7.5158963],\n",
        "      [11.7,7.098169],\n",
        "      [12.6,6.111024],\n",
        "      [13.5,5.6323136],\n",
        "      [14.4,5.2216917],\n",
        "      [15.3,5],\n",
        "      [16.2,4.9529667],\n",
        "      [17.1,4.8],\n",
        "      [18,4.7],\n",
        "      [18.9,4.6],\n",
        "      [19.8,4.5],\n",
        "      [20.7,4.4],\n",
        "      [21.6,4.3],\n",
        "      [22.5,4.2],\n",
        "      [23.4,4.1],\n",
        "      [24.3,4],\n",
        "      [25.2,3.9],\n",
        "      [26.1,3.8],\n",
        "      [27,3.7],\n",
        "      [27.9,3.6],\n",
        "      [28.8,3.5],\n",
        "      [29.7,3.2],\n",
        "      [30.6,3],\n",
        "      [60,0.0],\n",
        "\n",
        "      [120,-6],    #horizon\n",
        "\n",
        "      [40,1.98],\n",
        "      [50,1.33]\n",
        "\n",
        "       ]   #for extrapolation\n",
        "\n",
        "#=========================================================================================\n",
        "\n",
        "equiv2=[[1,41.05157], #1yard  0302\n",
        "        [1,42.18351],\n",
        "        [1,31.304607],\n",
        "        [1,25.090006],\n",
        "        [1,23.275448], #5yard 0306\n",
        "        [1,19.171278],\n",
        "        [1,17.472866],\n",
        "        [1,16.775742],\n",
        "        [1,15.820402],\n",
        "        [1,15.538459], #10yard  0311\n",
        "        [1,14.466544],\n",
        "        [1,12.707126],\n",
        "        [1,10.957558],\n",
        "\n",
        "\n",
        "        [1,6.023936],#'''inacurrate'''\n",
        "        [1,9.797453],  #15yard 0316\n",
        "        [1,7.2150397],\n",
        "        [1,6.3944836],\n",
        "        [1,8.514687],\n",
        "        [1,7.735209],\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt4BAs1zhPp3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import Rbf, InterpolatedUnivariateSpline\n",
        "equiv=np.asarray(equiv)\n",
        "X = equiv[:,1]    #midas output\n",
        "Y=equiv[:,0]     #meters\n",
        "new_length = 25\n",
        "new_x = np.linspace(X.min(), X.max(), new_length)\n",
        "conv=sp.interpolate.interp1d(X, Y, kind='linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2Fd1wKnhUqf"
      },
      "source": [
        "#Increased contrast\n",
        "Just to get increased contrast, not values in meters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpDq3tgxhQV4"
      },
      "outputs": [],
      "source": [
        "coef_expand=[[-5,-1],\n",
        "        [1,10],\n",
        "        [5,25],\n",
        "        [10,35],\n",
        "        [15,42],\n",
        "        [35,43],\n",
        "        [45,50],\n",
        "        [51,51]\n",
        "        ]\n",
        "coef_expand=np.asarray(coef_expand)\n",
        "X = coef_expand[:,0]    #midas output\n",
        "Y=coef_expand[:,1]      #meters\n",
        "expand=sp.interpolate.interp1d(X, Y, kind='cubic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q99un1SR_xll"
      },
      "source": [
        "# Segmented Point Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-QtEEGNGcuH"
      },
      "outputs": [],
      "source": [
        "from math import sin,cos,atan2\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "def depth2pcd_segm(depth,seg_map):\n",
        "    # print(depth)\n",
        "    # print(seg_map)\n",
        "    width = depth.shape[1]\n",
        "    height = depth.shape[0]\n",
        "    # print(width)\n",
        "    # print(height)\n",
        "    fx= 926.9796142578125\n",
        "    fy= 924.431884765625\n",
        "    cx= 790.234375\n",
        "    cy= 617.5499267578125\n",
        "    points = []\n",
        "    objects_needed = {'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "    'traffic sign', 'vegetation', 'terrain', 'person', 'rider', 'car', 'truck',\n",
        "    'bus', 'train', 'motorcycle', 'bicycle'}\n",
        "    objects_car = {'car'}\n",
        "    objects_wanted = {'car', 'trees','sidewalk'}\n",
        "\n",
        "\n",
        "    for v in range(0, width, 5):\n",
        "        # for u in range(0, height, 2):\n",
        "        for u in range(0, 1000, 5):\n",
        "            R = depth[u][v]\n",
        "            color = seg_map[u][v]\n",
        "            # print(R)\n",
        "            # print(color)\n",
        "            if R == 0:\n",
        "                continue\n",
        "\n",
        "            X_cam = (v - cx)\n",
        "            Y_cam = -(u - cy)\n",
        "\n",
        "            theta_x = atan2(X_cam,fx)\n",
        "            theta_y = atan2(Y_cam,fy)\n",
        "\n",
        "            X = R*cos(theta_y)*sin(theta_x)\n",
        "            Y = R*cos(theta_x)*sin(theta_y)\n",
        "            Z = R*cos(theta_x)*cos(theta_y)\n",
        "\n",
        "            if LABEL_NAMES[color] in objects_car:\n",
        "              # points.append([X, Y, Z])\n",
        "              points.append([X, Y, Z, color])\n",
        "            # points.append([X, Y, Z,color])\n",
        "\n",
        "    return np.array(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "refmmrWb_2eH"
      },
      "outputs": [],
      "source": [
        "def prediction_stream(image, seg_map, seg_data, frame, index):\n",
        "    \"\"\"Visualizes segmentation overlay view and stream it with IPython display.\"\"\"\n",
        "    for i in range(len(seg_map)):\n",
        "        for j in range(len(seg_map[i])):\n",
        "                seg_data[i][j] = LABEL_NAMES[seg_map[i][j]]\n",
        "\n",
        "\n",
        "\n",
        "    img = frame\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction = midas(input_batch)\n",
        "\n",
        "      prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "      ).squeeze()\n",
        "\n",
        "    output = prediction.cpu().numpy()\n",
        "    output = (output > 0) * output\n",
        "    distanceGuess = 2\n",
        "    alpha = output[output.shape[0]-10, int(output.shape[1]*3/4)]*distanceGuess\n",
        "    # output=expand(50*output/np.max(output)) # for better visualization\n",
        "    # output=conv(50*output/np.max(output))\n",
        "    output = alpha/(output+.001)\n",
        "    # print(output) # to get values in meters\n",
        "\n",
        "    # plt.imshow(output, cmap='plasma')\n",
        "\n",
        "    pc_3d = depth2pcd_segm(output,seg_map)\n",
        "    # if len(pc_3d) == 0:\n",
        "    #   fig = plt.figure(figsize=(12,6))\n",
        "    # else:\n",
        "    #   x = pc_3d[:, 0]\n",
        "    #   y = pc_3d[:, 1]\n",
        "    #   z = pc_3d[:, 2]\n",
        "    #   color = pc_3d[:, 3]\n",
        "    #   color_plot = np.zeros((len(color),3))\n",
        "    #   for i in range(len(color)):\n",
        "    #     color_plot[i] = COLOR_MAP[int(color[i])]\n",
        "\n",
        "    #   fig = plt.figure(figsize=(12,6))\n",
        "      # pc3dd = np.array([[x[i], z[i]] for i in range(len(x))])\n",
        "      # km = KMeans(n_clusters = 4)\n",
        "      # clusters= km.fit_predict(pc3dd)\n",
        "      # centroids = km.cluster_centers_\n",
        "      # points = np.empty((0,len(pc3dd[0])), float)\n",
        "      # # distances will be used to calculate outliers\n",
        "      # distances = np.empty((0,len(pc3dd[0])), float)\n",
        "      # # getting points and distances\n",
        "      # for i, center_elem in enumerate(centroids):\n",
        "      #     # cdist is used to calculate the distance between center and other points\n",
        "      #     distances = np.append(distances, cdist([center_elem],pc3dd[clusters == i], 'euclidean'))\n",
        "      #     points = np.append(points, pc3dd[clusters == i], axis=0)\n",
        "      # percentile = 90\n",
        "      # # getting outliers whose distances are greater than some percentile\n",
        "      # outliers = points[np.where(distances > np.percentile(distances, percentile))]\n",
        "      # #plotting outliers\n",
        "      # pc3dlast = C = np.array(list(filter(lambda x: x not in outliers, pc3dd)))\n",
        "      # plt.scatter(pc3dlast[:,0],pc3dlast[:,1],s=0.1)\n",
        "    #   plt.scatter(x,z,c=color_plot/255,s=0.1)\n",
        "    # plt.xlabel('Z')\n",
        "    # plt.ylabel('X')\n",
        "    # plt.xlim(-30, 30)\n",
        "    # plt.ylim(0, 30)\n",
        "\n",
        "    # plt.savefig('saved_figure.jpg')\n",
        "    # im = cv.imread('saved_figure.jpg')\n",
        "    # frames.append(im)\n",
        "    # plt.close()\n",
        "    # plt.imshow(expand(output), cmap='plasma')\n",
        "    # A = np.stack([seg_data,output])\n",
        "    # A = np.stack([seg_map,output])\n",
        "\n",
        "    # # Show visualization in a streaming fashion.\n",
        "    # f = BytesIO()\n",
        "    # plt.savefig(f, format='jpeg')\n",
        "    # IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "    # f.close()\n",
        "    # plt.close()\n",
        "    return pc_3d\n",
        "def prediction_video(frame, index):\n",
        "    \"\"\"Inferences DeepLab model on a video file and stream the visualization.\"\"\"\n",
        "    original_im = Image.fromarray(frame[..., ::-1])\n",
        "    seg_map = MODEL.run(original_im)\n",
        "    seg_data = np.full((len(seg_map),len(seg_map[0])),'nullvoidnada')\n",
        "    filled_seg_data = prediction_stream(original_im, seg_map, seg_data, frame, index)\n",
        "    # print(filled_seg_data)\n",
        "    return filled_seg_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV-Kk28ldELA",
        "outputId": "d803beb6-c96b-4dd2-fcb5-7855b70fd09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e88d1a3e1d0b>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  SAR_tracklog = np.array(SAR_tracklog)\n"
          ]
        }
      ],
      "source": [
        "# Get Map of Time frames of SAR to Camera, by finding nearest frames\n",
        "\n",
        "import pickle\n",
        "# os.chdir(\"Capstone-Updated/SAR+Camera_Fusion\")\n",
        "\n",
        "with open('camera_times.pickle', 'rb') as file:\n",
        "    camera_times = pickle.load(file)\n",
        "\n",
        "with open('sar_tracklog.pickle', 'rb') as file:\n",
        "    SAR_tracklog = pickle.load(file)\n",
        "\n",
        "SAR_tracklog = np.array(SAR_tracklog)\n",
        "SAR_times = SAR_tracklog[:,0]\n",
        "\n",
        "timestamp_map = np.zeros(len(SAR_times))\n",
        "\n",
        "j=0\n",
        "for i in range(len(SAR_times)):\n",
        "  while camera_times[j]<SAR_times[i]:\n",
        "    j+=1\n",
        "  timestamp_map[i] = j\n",
        "# print(timestamp_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7a_YXpaEno-"
      },
      "outputs": [],
      "source": [
        "camera_frames = []\n",
        "\n",
        "SAMPLE_VIDEO = 'camera.mp4'\n",
        "\n",
        "\n",
        "video = cv.VideoCapture(SAMPLE_VIDEO)\n",
        "total_frames = 1000\n",
        "\n",
        "try:\n",
        "    for i in range(total_frames):\n",
        "        _, frame = video.read()\n",
        "        if not _: break\n",
        "        camera_frames.append(frame)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    plt.close()\n",
        "    print(\"Stream stopped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_frames = 100\n",
        "pc3darray = []\n",
        "try:\n",
        "    for i in range(num_frames):\n",
        "      correct_frame = camera_frames[int(timestamp_map[i])]\n",
        "      filled_seg_DATA = prediction_video(correct_frame, int(timestamp_map[i]))\n",
        "      pc3darray.append(filled_seg_DATA)\n",
        "      IPython.display.clear_output(wait=True)\n",
        "except KeyboardInterrupt:\n",
        "    plt.close()\n",
        "    print(\"Stream stopped.\")\n",
        "\n",
        "del camera_frames"
      ],
      "metadata": {
        "id": "cDTweVt5SlFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5OVRWSXYUo4"
      },
      "source": [
        "# Convert Camera Frame to SAR frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pe_Qnn-DYafi"
      },
      "outputs": [],
      "source": [
        "#Transform a point [X,Y,Z] from the camera frame to the car frame (SAR)\n",
        "def Cam_ref_2_Car_ref(Pos_obj_cam):\n",
        "    #camera extrinsic (quaternion, translation)\n",
        "    R=[[ 0.99994752,  0.00325207,  0.00971481],\n",
        "    [-0.0030831 ,  0.99984459, -0.01735761],\n",
        "    [-0.00976975,  0.01732675,  0.99980215]]\n",
        "\n",
        "    T=[-0.41649988293647766, 0.09146018326282501, 0.011436160653829575]\n",
        "\n",
        "    Pos_obj_car = R@Pos_obj_cam[:3] + T\n",
        "    Pos_obj_car = np.append(Pos_obj_car,[Pos_obj_cam[-1]])\n",
        "    return Pos_obj_car"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tucOmzqbSK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79ab3e6-dfd3-4699-8731-6668b591353a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-20877346f290>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  pc3darray_SAR_frame = np.array(pc3darray_SAR_frame)\n"
          ]
        }
      ],
      "source": [
        "pc3darray_SAR_frame = []\n",
        "\n",
        "for i in range(len(pc3darray)):\n",
        "  pointcloud = []\n",
        "  for j in range(len(pc3darray[i])):\n",
        "    pointcloud.append(Cam_ref_2_Car_ref(pc3darray[i][j]))\n",
        "  pc3darray_SAR_frame.append(pointcloud)\n",
        "\n",
        "# print(Cam_ref_2_Car_ref(pc3darray[10]))\n",
        "\n",
        "pc3darray_SAR_frame = np.array(pc3darray_SAR_frame)\n",
        "del pc3darray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKc6MK8Hy_YJ"
      },
      "source": [
        "# SAR Video Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ32WSdJzDmb"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# SHRAVANs DRIVE\n",
        "# !ls \"/content/drive/My Drive/Capstone/SAR_data\"\n",
        "\n",
        "RADAR_VIDEO = 'radar_sar.mp4'\n",
        "CAMERA_VIDEO = 'camera.mp4'\n",
        "\n",
        "# # OMs DRIVE\n",
        "# !ls \"/content/drive/My Drive/Capstone/SAR_data\"\n",
        "\n",
        "# RADAR_VIDEO = '/content/drive/My Drive/Capstone/SAR_data/radar_sar.mp4'\n",
        "# CAMERA_VIDEO = '/content/drive/My Drive/Capstone/SAR_data/camera.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqhiiwnSHaB8"
      },
      "outputs": [],
      "source": [
        "def Convert_to_Meters(frame):\n",
        "  center_x = 625\n",
        "  center_y = 624\n",
        "  height, width = frame.shape\n",
        "\n",
        "  points = []\n",
        "\n",
        "  for v in range(0, width):\n",
        "        for u in range(0, height):\n",
        "          if frame[u][v]<200:\n",
        "            x = (v-center_x)*0.04\n",
        "            y = -(u-center_y)*0.04\n",
        "            points.append([x,y])\n",
        "  return np.array(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlWuU-x-zXSF"
      },
      "outputs": [],
      "source": [
        "def GetThreshold_Binary(frame):\n",
        "  gray_scale = 255 - cv.cvtColor(frame,cv.COLOR_RGB2GRAY)\n",
        "  threshold = 0.9*np.max(gray_scale)\n",
        "  _, thres = cv.threshold(gray_scale, threshold, 255,cv.THRESH_BINARY)\n",
        "  point_cloud = Convert_to_Meters(thres)\n",
        "  point_cloud = np.array(point_cloud)\n",
        "\n",
        "  # fig = plt.figure(figsize=(12,6))\n",
        "  # plt.scatter(point_cloud[:,0],point_cloud[:,1],s=0.1)\n",
        "  # plt.xlabel('Z')\n",
        "  # plt.ylabel('X')\n",
        "  # plt.xlim(-25, 25)\n",
        "  # plt.ylim(0, 25)\n",
        "\n",
        "  # plt.savefig('saved_figure.jpg')\n",
        "  # im = cv.imread('saved_figure.jpg')\n",
        "  # frames.append(im)\n",
        "  # plt.close()\n",
        "\n",
        "  return thres, point_cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o--rPYmC54_a"
      },
      "outputs": [],
      "source": [
        "def Plot_Camera_with_SAR(point_cloud_SAR, point_cloud_Camera):\n",
        "\n",
        "  fig = plt.figure(figsize=(12,6))\n",
        "  plt.scatter(point_cloud_SAR[:,0],point_cloud_SAR[:,1],s=0.1, color = 'black')\n",
        "\n",
        "  if len(point_cloud_Camera) > 0:\n",
        "    color = (point_cloud_Camera[:, 3])\n",
        "    color_plot = np.array([COLOR_MAP[int(c)] for c in color])\n",
        "    plt.scatter(point_cloud_Camera[:,0],point_cloud_Camera[:,2],s=0.1 , color = color_plot/255)\n",
        "  plt.xlabel('Z')\n",
        "  plt.ylabel('X')\n",
        "  plt.xlim(-25, 25)\n",
        "  plt.ylim(0, 25)\n",
        "\n",
        "  plt.savefig('saved_figure.jpg')\n",
        "  im = cv.imread('saved_figure.jpg')\n",
        "  frames.append(im)\n",
        "  plt.close()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPgKg5mNzpBh"
      },
      "outputs": [],
      "source": [
        "frames=[]\n",
        "video_radar = cv.VideoCapture(RADAR_VIDEO)\n",
        "\n",
        "radar_thresholded = np.zeros((num_frames,624,1250))\n",
        "\n",
        "SAR_points = []\n",
        "\n",
        "try:\n",
        "    for i in range(num_frames):\n",
        "        _, frame = video_radar.read()\n",
        "        if not _: break\n",
        "        radar_thresholded[i], points_SAR = GetThreshold_Binary(frame)\n",
        "        # A[i], points_SAR = GetThreshold_Adaptive(frame)\n",
        "        # A[i], points_SAR = GetThreshold_Gaussian(frame)\n",
        "\n",
        "        points_camera = np.array(pc3darray_SAR_frame[i])\n",
        "        Plot_Camera_with_SAR(points_SAR, points_camera)\n",
        "        SAR_points.append(points_SAR)\n",
        "\n",
        "        IPython.display.clear_output(wait=True)\n",
        "except KeyboardInterrupt:\n",
        "    plt.close()\n",
        "    print(\"Stream stopped.\")\n",
        "\n",
        "\n",
        "height, width, layers = frames[0].shape\n",
        "size = (width,height)\n",
        "fourcc = cv.VideoWriter_fourcc(*'MJPG')\n",
        "out = cv.VideoWriter('SARandCamera_pointcloud.avi', fourcc, 30.0, size)\n",
        "\n",
        "for i in range(len(frames)):\n",
        "    out.write(frames[i])\n",
        "out.release()\n",
        "\n",
        "\n",
        "SAR_points = np.array(radar_thresholded)\n",
        "Camera_points = np.array(pc3darray_SAR_frame)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sensor_points.npy', 'wb') as f:\n",
        "    np.save(f, SAR_points, allow_pickle= True)\n",
        "    np.save(f, Camera_points, allow_pickle = True)"
      ],
      "metadata": {
        "id": "Zklbd74lW8ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp sensor_points.npy /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "tT6y18w_cis9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kalman Filtering"
      ],
      "metadata": {
        "id": "oBi1_9momOAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "os.chdir(\"drive/MyDrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25QRuGIlmSU1",
        "outputId": "5da29c95-00b0-4eac-9c79-e734a704574a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('sensor_points_100_frames.npy', 'rb') as f:\n",
        "    sar_points = np.load(f, allow_pickle= True)\n",
        "    camera_points = np.load(f, allow_pickle= True)\n",
        "\n"
      ],
      "metadata": {
        "id": "uNqsFZZbYRBL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "occupancy_radar_points = sar_points.copy()\n",
        "\n",
        "print(\"k\",len(sar_points[0]))\n",
        "print(len(sar_points[0][0]))\n",
        "for i in range(len(camera_points)):\n",
        "  occupancy_map = {}\n",
        "  for j in range(len(camera_points[0])):\n",
        "    z = camera_points[i][j][0]\n",
        "    x = camera_points[i][j][2]\n",
        "    # print(x,z)\n",
        "    x_index = -1*int(x/.04) + 624\n",
        "    z_index = int(z/.04) + 650\n",
        "\n",
        "    x_index_2 = -1*round(x/.04) + 624\n",
        "    z_index_2 = round(z/.04) + 650\n",
        "\n",
        "    # print(x_index,z_index)\n",
        "    occupancy_map[(x_index,z_index)] = 1\n",
        "    occupancy_map[(x_index_2,z_index_2)] = 1\n",
        "\n",
        "  for k in range(len(sar_points[0])):\n",
        "    for l in range(len(sar_points[0][0])):\n",
        "      # print(k,l)\n",
        "      # print(l,k)\n",
        "      if ((k,l) in occupancy_map):\n",
        "          occupancy_radar_points[i][k][l] = 1\n",
        "      elif (sar_points[i][k][l] == 0.0):\n",
        "          occupancy_radar_points[i][k][l] = 0.1\n",
        "      else:\n",
        "          occupancy_radar_points[i][k][l] = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "PbmpoMd4TtyS",
        "outputId": "06c73aad-a0a2-475b-ccf1-65b8cb18dd48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k 624\n",
            "1250\n",
            "1000 -1000\n",
            "1000 -1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.imshow(occupancy_radar_points[0], interpolation='nearest', cmap = 'binary')\n"
      ],
      "metadata": {
        "id": "6KOzUdkbb1Vx",
        "outputId": "5f24f727-a675-4490-e148-dc30956485fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x787c2975fa60>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.imshow(sar_points[0], interpolation='nearest', origin='upper')\n",
        "print(sar_points[44][582][800])\n",
        "# ax.imshow(sar_points[32], interpolation='nearest', origin='upper')\n",
        "#Lower triangular matrix"
      ],
      "metadata": {
        "id": "kCIa8m10YMdk",
        "outputId": "b7dd2352-f263-45c4-eeb6-4a2c5ef26b2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bjBDj97y9k18",
        "3jKEwPDK-Edp",
        "Kja3q7PyhB4H",
        "s2Fd1wKnhUqf",
        "V5OVRWSXYUo4",
        "HKc6MK8Hy_YJ"
      ],
      "name": "SAR_and_Camera_PointCloud.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}