{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omprabhu98/MEngCapstone2022/blob/main/Sensor_Fusion_Camera_and_Radar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjBDj97y9k18"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vwz1UzMu9mF-",
        "outputId": "6e4b03bf-fb76-4521-bd89-6c6855fae478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ],
      "source": [
        "# Tensorflow\n",
        "import tensorflow.compat.v1 as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# I/O libraries\n",
        "import os\n",
        "from io import BytesIO\n",
        "import tarfile\n",
        "import tempfile\n",
        "from six.moves import urllib\n",
        "\n",
        "# Helper libraries\n",
        "import matplotlib\n",
        "import torch\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "from tqdm import tqdm\n",
        "import IPython\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Comment this out if you want to see Deprecation warnings\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
        "#test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwkf2tnYQKAT",
        "outputId": "d28d190f-1194-4ae1-ea55-ca0cb543ccc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (17.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.18.0 safetensors-0.4.0 timm-0.9.7\n"
          ]
        }
      ],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jKEwPDK-Edp"
      },
      "source": [
        "# Functions for Image Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "24Xfj_GZ-FWL"
      },
      "outputs": [],
      "source": [
        "class DeepLabModel(object):\n",
        "    \"\"\"Class to load deeplab model and run inference.\"\"\"\n",
        "\n",
        "    FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
        "\n",
        "    def __init__(self, tarball_path):\n",
        "        \"\"\"Creates and loads pretrained deeplab model.\"\"\"\n",
        "        self.graph = tf.Graph()\n",
        "        graph_def = None\n",
        "\n",
        "        # Extract frozen graph from tar archive.\n",
        "        tar_file = tarfile.open(tarball_path)\n",
        "        for tar_info in tar_file.getmembers():\n",
        "            if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
        "                file_handle = tar_file.extractfile(tar_info)\n",
        "                graph_def = tf.GraphDef.FromString(file_handle.read())\n",
        "                break\n",
        "        tar_file.close()\n",
        "\n",
        "        if graph_def is None:\n",
        "            raise RuntimeError('Cannot find inference graph in tar archive.')\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            tf.import_graph_def(graph_def, name='')\n",
        "        self.sess = tf.Session(graph=self.graph)\n",
        "\n",
        "    def run(self, image, INPUT_TENSOR_NAME = 'ImageTensor:0', OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'):\n",
        "        \"\"\"Runs inference on a single image.\n",
        "\n",
        "        Args:\n",
        "            image: A PIL.Image object, raw input image.\n",
        "            INPUT_TENSOR_NAME: The name of input tensor, default to ImageTensor.\n",
        "            OUTPUT_TENSOR_NAME: The name of output tensor, default to SemanticPredictions.\n",
        "\n",
        "        Returns:\n",
        "            resized_image: RGB image resized from original input image.\n",
        "            seg_map: Segmentation map of `resized_image`.\n",
        "        \"\"\"\n",
        "        width, height = image.size\n",
        "        target_size = (2049,1025)  # size of Cityscapes images\n",
        "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
        "        batch_seg_map = self.sess.run(\n",
        "            OUTPUT_TENSOR_NAME,\n",
        "            feed_dict={INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
        "        seg_map = batch_seg_map[0]  # expected batch size = 1\n",
        "        if len(seg_map.shape) == 2:\n",
        "            seg_map = np.expand_dims(seg_map,-1)  # need an extra dimension for cv.resize\n",
        "        seg_map = cv.resize(seg_map, (width,height), interpolation=cv.INTER_NEAREST)\n",
        "        return seg_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bCIUhvfV-MiI"
      },
      "outputs": [],
      "source": [
        "def create_label_colormap():\n",
        "    \"\"\"Creates a label colormap used in Cityscapes segmentation benchmark.\n",
        "\n",
        "    Returns:\n",
        "        A Colormap for visualizing segmentation results.\n",
        "    \"\"\"\n",
        "    colormap = np.array([\n",
        "        [128,  64, 128],\n",
        "        [244,  35, 232],\n",
        "        [ 70,  70,  70],\n",
        "        [102, 102, 156],\n",
        "        [190, 153, 153],\n",
        "        [153, 153, 153],\n",
        "        [250, 170,  30],\n",
        "        [220, 220,   0],\n",
        "        [107, 142,  35],\n",
        "        [152, 251, 152],\n",
        "        [ 70, 130, 180],\n",
        "        [220,  20,  60],\n",
        "        [255,   0,   0],\n",
        "        [  0,   0, 142],\n",
        "        [  0,   0,  70],\n",
        "        [  0,  60, 100],\n",
        "        [  0,  80, 100],\n",
        "        [  0,   0, 230],\n",
        "        [119,  11,  32],\n",
        "        [  0,   0,   0]], dtype=np.uint8)\n",
        "    return colormap\n",
        "\n",
        "\n",
        "def label_to_color_image(label):\n",
        "    \"\"\"Adds color defined by the dataset colormap to the label.\n",
        "\n",
        "    Args:\n",
        "        label: A 2D array with integer type, storing the segmentation label.\n",
        "\n",
        "    Returns:\n",
        "        result: A 2D array with floating type. The element of the array\n",
        "            is the color indexed by the corresponding element in the input label\n",
        "            to the PASCAL color map.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If label is not of rank 2 or its value is larger than color\n",
        "            map maximum entry.\n",
        "    \"\"\"\n",
        "    if label.ndim != 2:\n",
        "        raise ValueError('Expect 2-D input label')\n",
        "\n",
        "    colormap = create_label_colormap()\n",
        "\n",
        "    if np.max(label) >= len(colormap):\n",
        "        raise ValueError('label value too large.')\n",
        "\n",
        "    return colormap[label]\n",
        "\n",
        "\n",
        "def vis_segmentation(image, seg_map):\n",
        "    \"\"\"Visualizes input image, segmentation map and overlay view.\"\"\"\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    grid_spec = gridspec.GridSpec(1, 4, width_ratios=[6, 6, 6, 1])\n",
        "\n",
        "    plt.subplot(grid_spec[0])\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title('input image')\n",
        "\n",
        "    plt.subplot(grid_spec[1])\n",
        "    seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
        "    plt.imshow(seg_image)\n",
        "    plt.axis('off')\n",
        "    plt.title('segmentation map')\n",
        "\n",
        "    plt.subplot(grid_spec[2])\n",
        "    plt.imshow(image)\n",
        "    plt.imshow(seg_image, alpha=0.7)\n",
        "    plt.axis('off')\n",
        "    plt.title('segmentation overlay')\n",
        "\n",
        "    unique_labels = np.unique(seg_map)\n",
        "    ax = plt.subplot(grid_spec[3])\n",
        "    plt.imshow(FULL_COLOR_MAP[unique_labels].astype(np.uint8), interpolation='nearest')\n",
        "    ax.yaxis.tick_right()\n",
        "    plt.yticks(range(len(unique_labels)), LABEL_NAMES[unique_labels])\n",
        "    plt.xticks([], [])\n",
        "    ax.tick_params(width=0.0)\n",
        "    plt.grid('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "LABEL_NAMES = np.asarray([\n",
        "    'road', 'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "    'traffic sign', 'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck',\n",
        "    'bus', 'train', 'motorcycle', 'bicycle', 'void'])\n",
        "\n",
        "COLOR_MAP = np.array([\n",
        "    [128,  64, 128],\n",
        "    [244,  35, 232],\n",
        "    [ 70,  70,  70],\n",
        "    [102, 102, 156],\n",
        "    [190, 153, 153],\n",
        "    [153, 153, 153],\n",
        "    [250, 170,  30],\n",
        "    [220, 220,   0],\n",
        "    [107, 142,  35],\n",
        "    [152, 251, 152],\n",
        "    [ 70, 130, 180],\n",
        "    [220,  20,  60],\n",
        "    [255,   0,   0],\n",
        "    [  0,   0, 142],\n",
        "    [  0,   0,  70],\n",
        "    [  0,  60, 100],\n",
        "    [  0,  80, 100],\n",
        "    [  0,   0, 230],\n",
        "    [119,  11,  32],\n",
        "    [  0,   0,   0]], dtype=np.uint8)\n",
        "\n",
        "FULL_LABEL_MAP = np.arange(len(LABEL_NAMES)).reshape(len(LABEL_NAMES), 1)\n",
        "FULL_COLOR_MAP = label_to_color_image(FULL_LABEL_MAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxKiAGG_-QYw",
        "outputId": "38640ab4-a279-4f14-f210-8b6e0acffc8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading model, this might take a while...\n",
            "download completed! loading DeepLab model...\n",
            "model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'mobilenetv2_coco_cityscapes_trainfine'\n",
        "#MODEL_NAME = 'xception65_cityscapes_trainfine'\n",
        "\n",
        "_DOWNLOAD_URL_PREFIX = 'http://download.tensorflow.org/models/'\n",
        "_MODEL_URLS = {\n",
        "    'mobilenetv2_coco_cityscapes_trainfine':\n",
        "        'deeplabv3_mnv2_cityscapes_train_2018_02_05.tar.gz',\n",
        "    'xception65_cityscapes_trainfine':\n",
        "        'deeplabv3_cityscapes_train_2018_02_06.tar.gz',\n",
        "}\n",
        "_TARBALL_NAME = 'deeplab_model.tar.gz'\n",
        "\n",
        "model_dir = tempfile.mkdtemp()\n",
        "tf.gfile.MakeDirs(model_dir)\n",
        "\n",
        "download_path = os.path.join(model_dir, _TARBALL_NAME)\n",
        "print('downloading model, this might take a while...')\n",
        "urllib.request.urlretrieve(_DOWNLOAD_URL_PREFIX + _MODEL_URLS[MODEL_NAME], download_path)\n",
        "print('download completed! loading DeepLab model...')\n",
        "\n",
        "MODEL = DeepLabModel(download_path)\n",
        "print('model loaded successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVnUbIVY96HU"
      },
      "source": [
        "# Initialize Midas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW1E_emiQatf",
        "outputId": "297bb905-06fd-4c1d-9552-9db9bebb5e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/isl-org/MiDaS/releases/download/v3/dpt_large_384.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large_384.pt\n",
            "100%|██████████| 1.28G/1.28G [00:11<00:00, 117MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywJyJpTzQtDR",
        "outputId": "c2fd4eea-d0c6-452a-a91a-d64ab5df5df2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DPTDepthModel(\n",
              "  (pretrained): Module(\n",
              "    (model): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (patch_drop): Identity()\n",
              "      (norm_pre): Identity()\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (q_norm): Identity()\n",
              "            (k_norm): Identity()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (norm): Identity()\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head_drop): Dropout(p=0.0, inplace=False)\n",
              "      (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    )\n",
              "    (act_postprocess1): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "    )\n",
              "    (act_postprocess2): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (act_postprocess3): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act_postprocess4): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (scratch): Module(\n",
              "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (refinenet1): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet2): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet3): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet4): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (output_conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Interpolate()\n",
              "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4Da96O0Q06Z",
        "outputId": "7c237273-e324-491b-8ef1-3ff109eea177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN0kU6NJ1Ye5",
        "outputId": "d5feea78-e681-4d19-d6b9-7c32bdce706d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdsigyfAhITX",
        "outputId": "1d199a46-f8da-403d-9d58-40ba2a4540b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Capstone-Updated'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 246 (delta 13), reused 23 (delta 13), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (246/246), 217.56 MiB | 43.97 MiB/s, done.\n",
            "Resolving deltas: 100% (128/128), done.\n",
            "Capstone-Updated  sample_data\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Mmengyw/Capstone-Updated.git\n",
        "!ls\n",
        "os.chdir(\"Capstone-Updated/Videos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kja3q7PyhB4H"
      },
      "source": [
        "# Conversion to meters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LoPzjnl5hCCS"
      },
      "outputs": [],
      "source": [
        "nb_photo=34\n",
        "\n",
        "equiv=[[0.001,51],    #for extrapolation\n",
        "      [0.1,45],     #premier plan\n",
        "      [0.9,42.3],\n",
        "      [1.8,37.4],\n",
        "      [2.7,28.7],\n",
        "      [3.6,24.443365],\n",
        "      [4.5,22.058018],\n",
        "      [5.4,15.317413],\n",
        "      [6.3,14.677493],\n",
        "      [7.2,10.969739],\n",
        "      [8.1,10.883035],\n",
        "      [9,9.883035],\n",
        "      [9.9,8.058806],\n",
        "      [10.8,7.5158963],\n",
        "      [11.7,7.098169],\n",
        "      [12.6,6.111024],\n",
        "      [13.5,5.6323136],\n",
        "      [14.4,5.2216917],\n",
        "      [15.3,5],\n",
        "      [16.2,4.9529667],\n",
        "      [17.1,4.8],\n",
        "      [18,4.7],\n",
        "      [18.9,4.6],\n",
        "      [19.8,4.5],\n",
        "      [20.7,4.4],\n",
        "      [21.6,4.3],\n",
        "      [22.5,4.2],\n",
        "      [23.4,4.1],\n",
        "      [24.3,4],\n",
        "      [25.2,3.9],\n",
        "      [26.1,3.8],\n",
        "      [27,3.7],\n",
        "      [27.9,3.6],\n",
        "      [28.8,3.5],\n",
        "      [29.7,3.2],\n",
        "      [30.6,3],\n",
        "      [60,0.0],\n",
        "\n",
        "      [120,-6],    #horizon\n",
        "\n",
        "      [40,1.98],\n",
        "      [50,1.33]\n",
        "\n",
        "       ]   #for extrapolation\n",
        "\n",
        "#=========================================================================================\n",
        "\n",
        "equiv2=[[1,41.05157], #1yard  0302\n",
        "        [1,42.18351],\n",
        "        [1,31.304607],\n",
        "        [1,25.090006],\n",
        "        [1,23.275448], #5yard 0306\n",
        "        [1,19.171278],\n",
        "        [1,17.472866],\n",
        "        [1,16.775742],\n",
        "        [1,15.820402],\n",
        "        [1,15.538459], #10yard  0311\n",
        "        [1,14.466544],\n",
        "        [1,12.707126],\n",
        "        [1,10.957558],\n",
        "\n",
        "\n",
        "        [1,6.023936],#'''inacurrate'''\n",
        "        [1,9.797453],  #15yard 0316\n",
        "        [1,7.2150397],\n",
        "        [1,6.3944836],\n",
        "        [1,8.514687],\n",
        "        [1,7.735209],\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Wt4BAs1zhPp3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import Rbf, InterpolatedUnivariateSpline\n",
        "equiv=np.asarray(equiv)\n",
        "X = equiv[:,1]    #midas output\n",
        "Y=equiv[:,0]     #meters\n",
        "new_length = 25\n",
        "new_x = np.linspace(X.min(), X.max(), new_length)\n",
        "conv=sp.interpolate.interp1d(X, Y, kind='linear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2Fd1wKnhUqf"
      },
      "source": [
        "#Increased contrast\n",
        "Just to get increased contrast, not values in meters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VpDq3tgxhQV4"
      },
      "outputs": [],
      "source": [
        "coef_expand=[[-5,-1],\n",
        "        [1,10],\n",
        "        [5,25],\n",
        "        [10,35],\n",
        "        [15,42],\n",
        "        [35,43],\n",
        "        [45,50],\n",
        "        [51,51]\n",
        "        ]\n",
        "coef_expand=np.asarray(coef_expand)\n",
        "X = coef_expand[:,0]    #midas output\n",
        "Y=coef_expand[:,1]      #meters\n",
        "expand=sp.interpolate.interp1d(X, Y, kind='cubic')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q99un1SR_xll"
      },
      "source": [
        "# Segmented Point Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c-QtEEGNGcuH"
      },
      "outputs": [],
      "source": [
        "from math import sin,cos,atan2\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "def depth2pcd_segm(depth,seg_map):\n",
        "    # print(depth)\n",
        "    # print(seg_map)\n",
        "    width = depth.shape[1]\n",
        "    height = depth.shape[0]\n",
        "    # print(width)\n",
        "    # print(height)\n",
        "    fx= 926.9796142578125\n",
        "    fy= 924.431884765625\n",
        "    cx= 790.234375\n",
        "    cy= 617.5499267578125\n",
        "    points = []\n",
        "    objects_needed = {'sidewalk', 'building', 'wall', 'fence', 'pole', 'traffic light',\n",
        "    'traffic sign', 'vegetation', 'terrain', 'person', 'rider', 'car', 'truck',\n",
        "    'bus', 'train', 'motorcycle', 'bicycle'}\n",
        "    objects_car = {'car'}\n",
        "    objects_wanted = {'car', 'trees','sidewalk'}\n",
        "\n",
        "\n",
        "    for v in range(0, width, 5):\n",
        "        # for u in range(0, height, 2):\n",
        "        for u in range(0, 1000, 5):\n",
        "            R = depth[u][v]\n",
        "            color = seg_map[u][v]\n",
        "            # print(R)\n",
        "            # print(color)\n",
        "            if R == 0:\n",
        "                continue\n",
        "\n",
        "            X_cam = (v - cx)\n",
        "            Y_cam = -(u - cy)\n",
        "\n",
        "            theta_x = atan2(X_cam,fx)\n",
        "            theta_y = atan2(Y_cam,fy)\n",
        "\n",
        "            X = R*cos(theta_y)*sin(theta_x)\n",
        "            Y = R*cos(theta_x)*sin(theta_y)\n",
        "            Z = R*cos(theta_x)*cos(theta_y)\n",
        "\n",
        "            if LABEL_NAMES[color] in objects_wanted:\n",
        "              # points.append([X, Y, Z])\n",
        "              points.append([X, Y, Z,color])\n",
        "            # points.append([X, Y, Z,color])\n",
        "\n",
        "    return np.array(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "refmmrWb_2eH"
      },
      "outputs": [],
      "source": [
        "def prediction_stream(image, seg_map, seg_data, frame, index):\n",
        "    \"\"\"Visualizes segmentation overlay view and stream it with IPython display.\"\"\"\n",
        "    for i in range(len(seg_map)):\n",
        "        for j in range(len(seg_map[i])):\n",
        "                seg_data[i][j] = LABEL_NAMES[seg_map[i][j]]\n",
        "\n",
        "\n",
        "\n",
        "    img = frame\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction = midas(input_batch)\n",
        "\n",
        "      prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "      ).squeeze()\n",
        "\n",
        "    output = prediction.cpu().numpy()\n",
        "    output = (output > 0) * output\n",
        "    distanceGuess = 2\n",
        "    alpha = output[output.shape[0]-10, int(output.shape[1]*3/4)]*distanceGuess\n",
        "    # output=expand(50*output/np.max(output)) # for better visualization\n",
        "    # output=conv(50*output/np.max(output))\n",
        "    output = alpha/(output+.001)\n",
        "    # print(output) # to get values in meters\n",
        "\n",
        "    # plt.imshow(output, cmap='plasma')\n",
        "\n",
        "    pc_3d = depth2pcd_segm(output,seg_map)\n",
        "    # if len(pc_3d) == 0:\n",
        "    #   fig = plt.figure(figsize=(12,6))\n",
        "    # else:\n",
        "    #   x = pc_3d[:, 0]\n",
        "    #   y = pc_3d[:, 1]\n",
        "    #   z = pc_3d[:, 2]\n",
        "    #   color = pc_3d[:, 3]\n",
        "    #   color_plot = np.zeros((len(color),3))\n",
        "    #   for i in range(len(color)):\n",
        "    #     color_plot[i] = COLOR_MAP[int(color[i])]\n",
        "\n",
        "    #   fig = plt.figure(figsize=(12,6))\n",
        "      # pc3dd = np.array([[x[i], z[i]] for i in range(len(x))])\n",
        "      # km = KMeans(n_clusters = 4)\n",
        "      # clusters= km.fit_predict(pc3dd)\n",
        "      # centroids = km.cluster_centers_\n",
        "      # points = np.empty((0,len(pc3dd[0])), float)\n",
        "      # # distances will be used to calculate outliers\n",
        "      # distances = np.empty((0,len(pc3dd[0])), float)\n",
        "      # # getting points and distances\n",
        "      # for i, center_elem in enumerate(centroids):\n",
        "      #     # cdist is used to calculate the distance between center and other points\n",
        "      #     distances = np.append(distances, cdist([center_elem],pc3dd[clusters == i], 'euclidean'))\n",
        "      #     points = np.append(points, pc3dd[clusters == i], axis=0)\n",
        "      # percentile = 90\n",
        "      # # getting outliers whose distances are greater than some percentile\n",
        "      # outliers = points[np.where(distances > np.percentile(distances, percentile))]\n",
        "      # #plotting outliers\n",
        "      # pc3dlast = C = np.array(list(filter(lambda x: x not in outliers, pc3dd)))\n",
        "      # plt.scatter(pc3dlast[:,0],pc3dlast[:,1],s=0.1)\n",
        "    #   plt.scatter(x,z,c=color_plot/255,s=0.1)\n",
        "    # plt.xlabel('Z')\n",
        "    # plt.ylabel('X')\n",
        "    # plt.xlim(-30, 30)\n",
        "    # plt.ylim(0, 30)\n",
        "\n",
        "    # plt.savefig('saved_figure.jpg')\n",
        "    # im = cv.imread('saved_figure.jpg')\n",
        "    # frames.append(im)\n",
        "    # plt.close()\n",
        "    # plt.imshow(expand(output), cmap='plasma')\n",
        "    # A = np.stack([seg_data,output])\n",
        "    # A = np.stack([seg_map,output])\n",
        "\n",
        "    # # Show visualization in a streaming fashion.\n",
        "    # f = BytesIO()\n",
        "    # plt.savefig(f, format='jpeg')\n",
        "    # IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
        "    # f.close()\n",
        "    # plt.close()\n",
        "    return pc_3d\n",
        "def prediction_video(frame, index):\n",
        "    \"\"\"Inferences DeepLab model on a video file and stream the visualization.\"\"\"\n",
        "    original_im = Image.fromarray(frame[..., ::-1])\n",
        "    seg_map = MODEL.run(original_im)\n",
        "    seg_data = np.full((len(seg_map),len(seg_map[0])),'nullvoidnada')\n",
        "    filled_seg_data = prediction_stream(original_im, seg_map, seg_data, frame, index)\n",
        "    # print(filled_seg_data)\n",
        "    return filled_seg_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zV-Kk28ldELA",
        "outputId": "f78cfb52-7993-4f6d-a634-5ab23db26ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e88d1a3e1d0b>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  SAR_tracklog = np.array(SAR_tracklog)\n"
          ]
        }
      ],
      "source": [
        "# Get Map of Time frames of SAR to Camera, by finding nearest frames\n",
        "\n",
        "import pickle\n",
        "# os.chdir(\"Capstone-Updated/SAR+Camera_Fusion\")\n",
        "\n",
        "with open('camera_times.pickle', 'rb') as file:\n",
        "    camera_times = pickle.load(file)\n",
        "\n",
        "with open('sar_tracklog.pickle', 'rb') as file:\n",
        "    SAR_tracklog = pickle.load(file)\n",
        "\n",
        "SAR_tracklog = np.array(SAR_tracklog)\n",
        "SAR_times = SAR_tracklog[:,0]\n",
        "\n",
        "timestamp_map = np.zeros(len(SAR_times))\n",
        "\n",
        "j=0\n",
        "for i in range(len(SAR_times)):\n",
        "  while camera_times[j]<SAR_times[i]:\n",
        "    j+=1\n",
        "  timestamp_map[i] = j\n",
        "# print(timestamp_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7a_YXpaEno-",
        "outputId": "b3d32864-c088-4879-8654-47264f7ae5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199\n"
          ]
        }
      ],
      "source": [
        "frames = []\n",
        "pc3darray = []\n",
        "# SAMPLE_VIDEO = 'camera30fps.mp4'\n",
        "SAMPLE_VIDEO = 'camera.mp4'\n",
        "print('running deeplab on the sample video...')\n",
        "\n",
        "video = cv.VideoCapture(SAMPLE_VIDEO)\n",
        "# num_frames = 598  # uncomment to use the full sample video\n",
        "num_frames = 200\n",
        "\n",
        "try:\n",
        "    for i in range(num_frames):\n",
        "        _, frame = video.read()\n",
        "        if not _: break\n",
        "        print(i)\n",
        "        filled_seg_DATA = prediction_video(frame, int(timestamp_map[i]))\n",
        "        pc3darray.append(filled_seg_DATA)\n",
        "        IPython.display.clear_output(wait=True)\n",
        "except KeyboardInterrupt:\n",
        "    plt.close()\n",
        "    print(\"Stream stopped.\")\n",
        "# print(filled_seg_DATA)\n",
        "\n",
        "\n",
        "# height, width, layers = frames[0].shape\n",
        "# size = (width,height)\n",
        "# fourcc = cv.VideoWriter_fourcc(*'MJPG')\n",
        "# out = cv.VideoWriter('new_3D_pointcloud_wanted.avi', fourcc, 30.0, size)\n",
        "\n",
        "# for i in range(len(frames)):\n",
        "#     out.write(frames[i])\n",
        "# out.release()\n",
        "\n",
        "# pc3darray = np.array(pc3darray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5OVRWSXYUo4"
      },
      "source": [
        "# Convert Camera Frame to SAR frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pe_Qnn-DYafi"
      },
      "outputs": [],
      "source": [
        "#Transform a point [X,Y,Z] from the camera frame to the car frame (SAR)\n",
        "def Cam_ref_2_Car_ref(Pos_obj_cam):\n",
        "    #camera extrinsic (quaternion, translation)\n",
        "    R=[[ 0.99994752,  0.00325207,  0.00971481],\n",
        "    [-0.0030831 ,  0.99984459, -0.01735761],\n",
        "    [-0.00976975,  0.01732675,  0.99980215]]\n",
        "\n",
        "    T=[-0.41649988293647766, 0.09146018326282501, 0.011436160653829575]\n",
        "\n",
        "    Pos_obj_car = R@Pos_obj_cam[:3] + T\n",
        "    Pos_obj_car = np.append(Pos_obj_car,[Pos_obj_cam[-1]])\n",
        "    return Pos_obj_car"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tucOmzqbSK-",
        "outputId": "a76fd894-f510-4225-af93-bd614eb05330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-e9a5f79602fa>:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  pc3darray_SAR_frame = np.array(pc3darray_SAR_frame)\n"
          ]
        }
      ],
      "source": [
        "pc3darray_SAR_frame = []\n",
        "\n",
        "for i in range(len(pc3darray)):\n",
        "  pointcloud = []\n",
        "  for j in range(len(pc3darray[i])):\n",
        "    pointcloud.append(Cam_ref_2_Car_ref(pc3darray[i][j]))\n",
        "  pc3darray_SAR_frame.append(pointcloud)\n",
        "\n",
        "# print(Cam_ref_2_Car_ref(pc3darray[10]))\n",
        "\n",
        "pc3darray_SAR_frame = np.array(pc3darray_SAR_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "HFxbZhGc1Anl",
        "outputId": "bd7303b1-1492-49cc-b39d-a58991da4b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-10.0594986   -1.6534918   11.51367973   1.        ]\n",
            "1.0\n",
            "[244  35 232]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "coord = np.array(pc3darray_SAR_frame[39])\n",
        "print(coord[1])\n",
        "plt.scatter(coord[:,0],coord[:,2],s = 0.2)\n",
        "print(coord[1,3])\n",
        "print(COLOR_MAP[int(coord[1,3])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7q2x5oGBQdo",
        "outputId": "faae0dbc-5bf9-4101-f198-f7564639c035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1.0, 13.0}\n"
          ]
        }
      ],
      "source": [
        "col = set(coord[:,3])\n",
        "print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKc6MK8Hy_YJ"
      },
      "source": [
        "# SAR Video Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yZ32WSdJzDmb"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# SHRAVANs DRIVE\n",
        "# !ls \"/content/drive/My Drive/Capstone/SAR_data\"\n",
        "\n",
        "RADAR_VIDEO = 'radar_sar.mp4'\n",
        "CAMERA_VIDEO = 'camera.mp4'\n",
        "\n",
        "# # OMs DRIVE\n",
        "# !ls \"/content/drive/My Drive/Capstone/SAR_data\"\n",
        "\n",
        "# RADAR_VIDEO = '/content/drive/My Drive/Capstone/SAR_data/radar_sar.mp4'\n",
        "# CAMERA_VIDEO = '/content/drive/My Drive/Capstone/SAR_data/camera.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eqhiiwnSHaB8"
      },
      "outputs": [],
      "source": [
        "def Convert_to_Meters(frame):\n",
        "  center_x = 625\n",
        "  center_y = 624\n",
        "  height, width = frame.shape\n",
        "\n",
        "  points = []\n",
        "\n",
        "  for v in range(0, width):\n",
        "        for u in range(0, height):\n",
        "          if frame[u][v]<200:\n",
        "            x = (v-center_x)*0.04\n",
        "            y = -(u-center_y)*0.04\n",
        "            points.append([x,y])\n",
        "  return np.array(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RlWuU-x-zXSF"
      },
      "outputs": [],
      "source": [
        "def GetThreshold_Binary(frame):\n",
        "  gray_scale = 255 - cv.cvtColor(frame,cv.COLOR_RGB2GRAY)\n",
        "  threshold = 0.9*np.max(gray_scale)\n",
        "  _, thres = cv.threshold(gray_scale, threshold, 255,cv.THRESH_BINARY)\n",
        "  point_cloud = Convert_to_Meters(thres)\n",
        "  point_cloud = np.array(point_cloud)\n",
        "\n",
        "  # fig = plt.figure(figsize=(12,6))\n",
        "  # plt.scatter(point_cloud[:,0],point_cloud[:,1],s=0.1)\n",
        "  # plt.xlabel('Z')\n",
        "  # plt.ylabel('X')\n",
        "  # plt.xlim(-25, 25)\n",
        "  # plt.ylim(0, 25)\n",
        "\n",
        "  # plt.savefig('saved_figure.jpg')\n",
        "  # im = cv.imread('saved_figure.jpg')\n",
        "  # frames.append(im)\n",
        "  # plt.close()\n",
        "\n",
        "  return thres, point_cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "msOjRuVCHRjQ"
      },
      "outputs": [],
      "source": [
        "def GetThreshold_Adaptive(frame):\n",
        "  gray_scale = 255 - cv.cvtColor(frame,cv.COLOR_RGB2GRAY)\n",
        "  thres = cv.adaptiveThreshold(gray_scale,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,11,10)\n",
        "  point_cloud = Convert_to_Meters(thres)\n",
        "  point_cloud = np.array(point_cloud)\n",
        "\n",
        "  # fig = plt.figure(figsize=(12,6))\n",
        "  # plt.scatter(point_cloud[:,0],point_cloud[:,1],s=0.1)\n",
        "  # plt.xlabel('Z')\n",
        "  # plt.ylabel('X')\n",
        "  # plt.xlim(-25, 25)\n",
        "  # plt.ylim(0, 25)\n",
        "\n",
        "  # plt.savefig('saved_figure.jpg')\n",
        "  # im = cv.imread('saved_figure.jpg')\n",
        "  # frames.append(im)\n",
        "  # plt.close()\n",
        "\n",
        "  return thres, point_cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rdGGz5yHHTOy"
      },
      "outputs": [],
      "source": [
        "def GetThreshold_Gaussian(frame):\n",
        "  gray_scale = 255 - cv.cvtColor(frame,cv.COLOR_RGB2GRAY)\n",
        "  thres = cv.adaptiveThreshold(gray_scale,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY,21,10)\n",
        "  point_cloud = Convert_to_Meters(thres)\n",
        "  point_cloud = np.array(point_cloud)\n",
        "\n",
        "  # fig = plt.figure(figsize=(12,6))\n",
        "  # plt.scatter(point_cloud[:,0],point_cloud[:,1],s=0.1)\n",
        "  # plt.xlabel('Z')\n",
        "  # plt.ylabel('X')\n",
        "  # plt.xlim(-25, 25)\n",
        "  # plt.ylim(0, 25)\n",
        "\n",
        "  # plt.savefig('saved_figure.jpg')\n",
        "  # im = cv.imread('saved_figure.jpg')\n",
        "  # frames.append(im)\n",
        "  # plt.close()\n",
        "\n",
        "  return thres, point_cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "o--rPYmC54_a"
      },
      "outputs": [],
      "source": [
        "def Plot_Camera_with_SAR(point_cloud_SAR, point_cloud_Camera):\n",
        "\n",
        "  fig = plt.figure(figsize=(12,6))\n",
        "  plt.scatter(point_cloud_SAR[:,0],point_cloud_SAR[:,1],s=0.1, color = 'black')\n",
        "\n",
        "  if len(point_cloud_Camera)>0:\n",
        "    color = (point_cloud_Camera[:, 3])\n",
        "    color_plot = np.array([COLOR_MAP[int(c)] for c in color])\n",
        "    # print(color_plot)\n",
        "    plt.scatter(point_cloud_Camera[:,0],point_cloud_Camera[:,2],s=0.1 , color = color_plot/255)\n",
        "  plt.xlabel('Z')\n",
        "  plt.ylabel('X')\n",
        "  plt.xlim(-25, 25)\n",
        "  plt.ylim(0, 25)\n",
        "\n",
        "  plt.savefig('saved_figure.jpg')\n",
        "  im = cv.imread('saved_figure.jpg')\n",
        "  frames.append(im)\n",
        "  plt.close()\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPgKg5mNzpBh",
        "outputId": "3ae5e60f-d61d-4f08-fedc-a597b039c618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stream stopped.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-ab0652af5318>:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  SAR_points = np.array(SAR_points)\n"
          ]
        }
      ],
      "source": [
        "frames=[]\n",
        "video_radar = cv.VideoCapture(RADAR_VIDEO)\n",
        "# num_frames = 200\n",
        "\n",
        "\n",
        "A = np.zeros((num_frames,624,1250))\n",
        "\n",
        "SAR_points = []\n",
        "\n",
        "try:\n",
        "    for i in range(num_frames):\n",
        "        _, frame = video_radar.read()\n",
        "        if not _: break\n",
        "        print(i)\n",
        "        A[i], points_SAR= GetThreshold_Binary(frame)\n",
        "        # A[i], points_SAR = GetThreshold_Adaptive(frame)\n",
        "        # A[i], points_SAR = GetThreshold_Gaussian(frame)\n",
        "\n",
        "        points_camera = np.array(pc3darray_SAR_frame[i])\n",
        "        Plot_Camera_with_SAR(points_SAR, points_camera)\n",
        "        SAR_points.append(points_SAR)\n",
        "\n",
        "        IPython.display.clear_output(wait=True)\n",
        "except KeyboardInterrupt:\n",
        "    plt.close()\n",
        "    print(\"Stream stopped.\")\n",
        "\n",
        "\n",
        "height, width, layers = frames[0].shape\n",
        "size = (width,height)\n",
        "fourcc = cv.VideoWriter_fourcc(*'MJPG')\n",
        "out = cv.VideoWriter('SARandCamera_pointcloud.avi', fourcc, 30.0, size)\n",
        "\n",
        "for i in range(len(frames)):\n",
        "    out.write(frames[i])\n",
        "out.release()\n",
        "\n",
        "\n",
        "SAR_points = np.array(SAR_points)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bjBDj97y9k18",
        "3jKEwPDK-Edp",
        "Kja3q7PyhB4H",
        "s2Fd1wKnhUqf",
        "V5OVRWSXYUo4",
        "HKc6MK8Hy_YJ"
      ],
      "name": "SAR_and_Camera_PointCloud.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}